{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you Chitta Ranjan for the real world dataset of sheet break on a paper mill. It is a challeging time series dataset and a common problem on predictive maintanance domain.\n",
    "This article propose a feasible and straight forward solution for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive maintanance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the predictive maintanance domain a challenging that many companies are facing are predict failures \n",
    "before its ocurrence based on the equipment behavior (Condition Based Maintanance).\n",
    "A common tool used today for maintanance crew are risk and realiability tools (based on Weibull curves for example).\n",
    "Sumarizing: the idea is to separate the failures on a probability curve with 3 distinct areas: premature failures, random failures and \n",
    "end of life failures.\n",
    "This is a simple ideia that can give us insights about features that are important on this domain, such as the clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p align=\"center\"><img border=\"0\" src=\"https://www.weibull.com/hotwire/issue14/rb14_6.gif\" alt=\"Plot of typical bathtub curve\" width=\"602\" height=\"353\"></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<p align=\"center\"><img border=\"0\" src=\"https://www.weibull.com/hotwire/issue14/rb14_6.gif\" alt=\"Plot of typical bathtub curve\" width=\"602\" height=\"353\"></p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysys on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing all the existing features, only x61 is freeze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "      <th>x61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18274.0</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.000000</td>\n",
       "      <td>18274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>0.194998</td>\n",
       "      <td>0.626211</td>\n",
       "      <td>-10.139593</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>2.489880</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>-0.004143</td>\n",
       "      <td>-0.003368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401567</td>\n",
       "      <td>0.458541</td>\n",
       "      <td>0.183983</td>\n",
       "      <td>2.454428</td>\n",
       "      <td>9.401764</td>\n",
       "      <td>0.236905</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.069369</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741833</td>\n",
       "      <td>4.912832</td>\n",
       "      <td>5.898330</td>\n",
       "      <td>130.983772</td>\n",
       "      <td>0.633845</td>\n",
       "      <td>36.987546</td>\n",
       "      <td>0.108664</td>\n",
       "      <td>0.075172</td>\n",
       "      <td>0.155036</td>\n",
       "      <td>...</td>\n",
       "      <td>6.052476</td>\n",
       "      <td>4.612143</td>\n",
       "      <td>3.023366</td>\n",
       "      <td>67.891696</td>\n",
       "      <td>81.289542</td>\n",
       "      <td>2.324591</td>\n",
       "      <td>0.048760</td>\n",
       "      <td>10.428501</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.787279</td>\n",
       "      <td>-17.316550</td>\n",
       "      <td>-18.198509</td>\n",
       "      <td>-322.781610</td>\n",
       "      <td>-1.623988</td>\n",
       "      <td>-279.408440</td>\n",
       "      <td>-0.429273</td>\n",
       "      <td>-0.451141</td>\n",
       "      <td>-0.120087</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.555008</td>\n",
       "      <td>-14.211369</td>\n",
       "      <td>-8.210370</td>\n",
       "      <td>-230.574030</td>\n",
       "      <td>-269.039500</td>\n",
       "      <td>-4.888661</td>\n",
       "      <td>-0.149790</td>\n",
       "      <td>-100.810500</td>\n",
       "      <td>-0.012229</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.405828</td>\n",
       "      <td>-2.123012</td>\n",
       "      <td>-3.477843</td>\n",
       "      <td>-111.428898</td>\n",
       "      <td>-0.446864</td>\n",
       "      <td>-23.687049</td>\n",
       "      <td>-0.058658</td>\n",
       "      <td>-0.050880</td>\n",
       "      <td>-0.059966</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.672684</td>\n",
       "      <td>-1.933476</td>\n",
       "      <td>0.492208</td>\n",
       "      <td>-39.882046</td>\n",
       "      <td>-45.399116</td>\n",
       "      <td>-1.598804</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.295016</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128147</td>\n",
       "      <td>-0.060635</td>\n",
       "      <td>-0.161470</td>\n",
       "      <td>-14.940988</td>\n",
       "      <td>-0.120699</td>\n",
       "      <td>10.585686</td>\n",
       "      <td>-0.009339</td>\n",
       "      <td>-0.000993</td>\n",
       "      <td>-0.030057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294846</td>\n",
       "      <td>0.144222</td>\n",
       "      <td>0.712452</td>\n",
       "      <td>17.633121</td>\n",
       "      <td>1.682657</td>\n",
       "      <td>0.085826</td>\n",
       "      <td>0.012867</td>\n",
       "      <td>0.733812</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>2.335692</td>\n",
       "      <td>3.443554</td>\n",
       "      <td>92.052390</td>\n",
       "      <td>0.326277</td>\n",
       "      <td>32.206184</td>\n",
       "      <td>0.060506</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>...</td>\n",
       "      <td>5.132737</td>\n",
       "      <td>3.237362</td>\n",
       "      <td>2.676296</td>\n",
       "      <td>44.113162</td>\n",
       "      <td>63.318964</td>\n",
       "      <td>2.222118</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>1.266258</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.054156</td>\n",
       "      <td>16.742105</td>\n",
       "      <td>15.900116</td>\n",
       "      <td>334.694098</td>\n",
       "      <td>2.371770</td>\n",
       "      <td>96.060768</td>\n",
       "      <td>1.705590</td>\n",
       "      <td>0.553834</td>\n",
       "      <td>4.060033</td>\n",
       "      <td>...</td>\n",
       "      <td>14.180588</td>\n",
       "      <td>11.148006</td>\n",
       "      <td>6.637265</td>\n",
       "      <td>287.252017</td>\n",
       "      <td>252.147455</td>\n",
       "      <td>6.922008</td>\n",
       "      <td>0.067249</td>\n",
       "      <td>6.985460</td>\n",
       "      <td>0.020510</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y            x1            x2            x3            x4  \\\n",
       "count  18274.0  18274.000000  18274.000000  18274.000000  18274.000000   \n",
       "mean       0.0      0.011198      0.194998      0.626211    -10.139593   \n",
       "std        0.0      0.741833      4.912832      5.898330    130.983772   \n",
       "min        0.0     -3.787279    -17.316550    -18.198509   -322.781610   \n",
       "25%        0.0     -0.405828     -2.123012     -3.477843   -111.428898   \n",
       "50%        0.0      0.128147     -0.060635     -0.161470    -14.940988   \n",
       "75%        0.0      0.420588      2.335692      3.443554     92.052390   \n",
       "max        0.0      3.054156     16.742105     15.900116    334.694098   \n",
       "\n",
       "                 x5            x6            x7            x8            x9  \\\n",
       "count  18274.000000  18274.000000  18274.000000  18274.000000  18274.000000   \n",
       "mean       0.006840      2.489880      0.001483     -0.004143     -0.003368   \n",
       "std        0.633845     36.987546      0.108664      0.075172      0.155036   \n",
       "min       -1.623988   -279.408440     -0.429273     -0.451141     -0.120087   \n",
       "25%       -0.446864    -23.687049     -0.058658     -0.050880     -0.059966   \n",
       "50%       -0.120699     10.585686     -0.009339     -0.000993     -0.030057   \n",
       "75%        0.326277     32.206184      0.060506      0.038986      0.001255   \n",
       "max        2.371770     96.060768      1.705590      0.553834      4.060033   \n",
       "\n",
       "       ...           x52           x53           x54           x55  \\\n",
       "count  ...  18274.000000  18274.000000  18274.000000  18274.000000   \n",
       "mean   ...      0.401567      0.458541      0.183983      2.454428   \n",
       "std    ...      6.052476      4.612143      3.023366     67.891696   \n",
       "min    ...    -16.555008    -14.211369     -8.210370   -230.574030   \n",
       "25%    ...     -3.672684     -1.933476      0.492208    -39.882046   \n",
       "50%    ...      0.294846      0.144222      0.712452     17.633121   \n",
       "75%    ...      5.132737      3.237362      2.676296     44.113162   \n",
       "max    ...     14.180588     11.148006      6.637265    287.252017   \n",
       "\n",
       "                x56           x57           x58           x59           x60  \\\n",
       "count  18274.000000  18274.000000  18274.000000  18274.000000  18274.000000   \n",
       "mean       9.401764      0.236905     -0.001881     -0.069369      0.001252   \n",
       "std       81.289542      2.324591      0.048760     10.428501      0.004718   \n",
       "min     -269.039500     -4.888661     -0.149790   -100.810500     -0.012229   \n",
       "25%      -45.399116     -1.598804      0.000473      0.295016     -0.001808   \n",
       "50%        1.682657      0.085826      0.012867      0.733812      0.000704   \n",
       "75%       63.318964      2.222118      0.020988      1.266258      0.004064   \n",
       "max      252.147455      6.922008      0.067249      6.985460      0.020510   \n",
       "\n",
       "           x61  \n",
       "count  18274.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./processminer-rare-event-mts - data.csv',sep=';')\n",
    "df[df.y==0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althought x61 has a small std it has some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df['x60'].loc[df.y==0].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and feature enginerring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Predictive Maintanance insight a feature that is missing is the clock or the cycle since the last break. \n",
    "It is a usefull information for the model to contextualized the anomalies on time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_change' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-21f8bc336bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from src.pyUtil import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'count_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'count_change' is not defined"
     ]
    }
   ],
   "source": [
    "from src.pyUtil import *\n",
    "df = count_change(df,'y','count_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose is to create an alert until 4 minutes before the break and eliminate the freezed feature(x61). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_1'] = df['y'].shift(-1)\n",
    "df['y_2'] = df['y'].shift(-2)\n",
    "df['y_3'] = df['y'].shift(-3)\n",
    "df = df.loc[df.y==0] #deleting the downtime event \n",
    "\n",
    "df['y'] = df.apply(lambda x: 1 if ((x['y_1'] == 1) | (x['y_2'] == 1)) else 0, axis=1) \n",
    "\n",
    "features = df.columns.tolist()# adding delayed info\n",
    "features.remove('time')\n",
    "features.remove('y_1')\n",
    "features.remove('y_2')\n",
    "features.remove('y_3')\n",
    "features.remove('x61')\n",
    "target = 'y'\n",
    "features.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hightlights: the time features were eliminated since the period of data (less than a month) do note justify \n",
    "create features like (hour, day, shift, quarter, day of week, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minory class is ~ 1.3% of all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.value_counts()[1] /(df.y.value_counts()[0] + df.y.value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple way to improve it a bit is to determine that 6 minutes before the event is as good as 4 minutes. \n",
    "So, it will improve 50% of minority class and it is fair to assert that is not a terible sin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df.apply(lambda x: 1 if ((x['y_1'] == 1) | (x['y_2'] == 1) | (x['y_3'] == 1) ) else 0, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvement on the unbalanced class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.value_counts()[1] /(df.y.value_counts()[0] + df.y.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This artificial features has the following behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=90)\n",
    "plt.plot(df['count_y'].iloc[0:1000])\n",
    "plt.ylabel('Time until break')\n",
    "plt.xlabel('Continous time')\n",
    "plt.text(200,300,'Break event',weight='bold')\n",
    "plt.text(350,20,'Fresh start',weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behavior of counter or clock since the last break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['y','count_y']].iloc[253:263]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will carry historical (10 minutes) information of the frame for a future analyis before splitting the data. It will be explained later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df.shift(1),rsuffix='_1').join(df.shift(2),rsuffix='_2').join(df.shift(3),rsuffix='_3').join(df.shift(4),rsuffix='_4').join(df.shift(5),rsuffix='_5')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be divides in train and test (without cross validation to simplify the approach). Test size at default 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features],df[target],\n",
    "                                                    shuffle=True, random_state=10)\n",
    "#Have a copy of the vector, just in case\n",
    "x_train_origin = x_train.copy()\n",
    "x_test_origin = x_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "x_train = pd.DataFrame(data=scale.fit_transform(x_train),columns=features,index=y_train.index)\n",
    "x_test = pd.DataFrame(data=scale.transform(x_test),columns=features,index=y_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection with one class strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest strategy for anomaly detection is to use one class algoritms such as SVM or Mahalanobis distance to \n",
    "understand what is normal in data and what is not normal. Somehow is the same with autoenconders used on the Chitta article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the anomaly detector alone and with all features the results are bellow the benchmark of F1 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting data\n",
    "xy_train = x_train.join(y_train)\n",
    "xy_train = xy_train.loc[(xy_train.y==0)]  # only normal\n",
    "\n",
    "x_train_pos, x_test_pos, y_train_pos, y_test_pos = train_test_split(xy_train[features], xy_train[target], shuffle=True,\n",
    "                                                                    train_size=0.9, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm1 = OneClassSVM(kernel='rbf', gamma='auto',nu=0.05)\n",
    "\n",
    "svm1.fit(x_train_pos[features])\n",
    "\n",
    "y_pred = pd.DataFrame(data=svm1.predict(x_test[features]))\n",
    "# need to convert to the same standard, 0 == normal and 1 for break\n",
    "y_pred.loc[y_pred[0]==1] = 0 # normal \n",
    "y_pred.loc[y_pred[0]==-1] = 1 #break\n",
    "\n",
    "print(classification_report(y_test,y_pred,digits=3))\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Mahalanobis One Class measuring the distance from the mean of the training data. There more sofisticated approaches \n",
    "but for this article we will apply a simpler solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Mahalanobis One Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "import scipy as sp\n",
    "\n",
    "def mahalanobis(x=None, data=None, cov=None):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n",
    "    x    : vector or matrix of data with, say, p columns.\n",
    "    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n",
    "    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n",
    "    based on https://www.machinelearningplus.com/statistics/mahalanobis-distance/\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(data).values.reshape(1,-1)#np.mean(data)\n",
    "    \n",
    "    if not cov:\n",
    "        cov = np.cov(data.values.T)\n",
    "    if cov.shape == (): #Maha in 1 dimension\n",
    "        cov = cov.reshape(1,1)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "   \n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return mahal.diagonal()\n",
    "\n",
    "class MahalanobisOneclassClassifier():\n",
    "    def __init__(self, xtrain, significance_level=0.01):\n",
    "        self.xtrain = xtrain\n",
    "        self.critical_value = chi2.ppf((1-significance_level), df=xtrain.shape[1]-1)\n",
    "        #print('Critical value is: ', self.critical_value)\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        mahalanobis_dist = mahalanobis(xtest, self.xtrain)\n",
    "        self.pvalues = 1 - chi2.cdf(mahalanobis_dist, 2)\n",
    "        return mahalanobis_dist\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([int(i) for i in self.predict_proba(xtest) > self.critical_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_total = MahalanobisOneclassClassifier(x_train_pos[features], significance_level=0.001)\n",
    "mahalanobis_dist_total = clf_total.predict_proba(x_test_pos[features].values)\n",
    "\n",
    "print(classification_report(y_test,clf_total.predict(x_test[features].values),digits=3))\n",
    "confusion_matrix(y_test,clf_total.predict(x_test[features].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small feature groups for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both algoritms were bellow benchmark alone using all the features. The dimension of the problem is surelly a complication\n",
    "for this type of algorithm. One possible strategy is to divide the features into afinity groups. Usually a good working session\n",
    "with the domain expert can help with that. An alternative is to use the GradientBoost Tree (features importance) to support\n",
    "this definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance\n",
    "gbc = XGBClassifier(n_estimators=1000,subsample=0.9,max_depth=6,random_state=10, max_features=0.9,n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time gbc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,50))\n",
    "plot_importance(gbc, ax=ax, height=1, importance_type=\"gain\", xlabel=\"Total Gain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be create groups of 2 tags for the top 20 indicated by the GradientBoost:(arbirtrary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_maha = ['x51', 'x28']\n",
    "feat_maha2 = ['x26', 'x43']\n",
    "feat_maha3 = ['x60', 'x8']\n",
    "feat_maha4 = ['x54', 'x50']\n",
    "feat_maha5 = ['x14', 'x18']\n",
    "feat_maha6 = ['x24', 'x53']\n",
    "feat_maha7 = ['x23', 'x15']\n",
    "feat_maha8 = ['x22', 'x52']\n",
    "feat_maha9 = ['x42', 'x21']\n",
    "feat_maha10 = ['x36', 'x3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the models              \n",
    "clf = MahalanobisOneclassClassifier(x_train_pos[feat_maha], significance_level=0.01)\n",
    "clf2 = MahalanobisOneclassClassifier(x_train_pos[feat_maha2], significance_level=0.01)\n",
    "clf3 = MahalanobisOneclassClassifier(x_train_pos[feat_maha3], significance_level=0.01)\n",
    "clf4 = MahalanobisOneclassClassifier(x_train_pos[feat_maha4], significance_level=0.01)\n",
    "clf5 = MahalanobisOneclassClassifier(x_train_pos[feat_maha5], significance_level=0.01)\n",
    "clf6 = MahalanobisOneclassClassifier(x_train_pos[feat_maha6], significance_level=0.01)\n",
    "clf7 = MahalanobisOneclassClassifier(x_train_pos[feat_maha7], significance_level=0.01)\n",
    "clf8 = MahalanobisOneclassClassifier(x_train_pos[feat_maha8], significance_level=0.01)\n",
    "clf9 = MahalanobisOneclassClassifier(x_train_pos[feat_maha9], significance_level=0.01)\n",
    "clf10 = MahalanobisOneclassClassifier(x_train_pos[feat_maha10], significance_level=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking with gradient boost\n",
    "df['maha_dist'] = clf.predict_proba(df[feat_maha].values)\n",
    "df['maha_dist2'] = clf2.predict_proba(df[feat_maha2].values)\n",
    "df['maha_dist3'] = clf3.predict_proba(df[feat_maha3].values)\n",
    "df['maha_dist4'] = clf4.predict_proba(df[feat_maha4].values)\n",
    "df['maha_dist5'] = clf5.predict_proba(df[feat_maha5].values)\n",
    "df['maha_dist6'] = clf6.predict_proba(df[feat_maha6].values)\n",
    "df['maha_dist7'] = clf7.predict_proba(df[feat_maha7].values)\n",
    "df['maha_dist8'] = clf8.predict_proba(df[feat_maha8].values)\n",
    "df['maha_dist9'] = clf9.predict_proba(df[feat_maha9].values)\n",
    "df['maha_dist10'] = clf10.predict_proba(df[feat_maha10].values)\n",
    "\n",
    "new_features = []\n",
    "for i in df.columns.tolist()[-10:]:\n",
    "    if not i in features:\n",
    "        features.append(i)\n",
    "        new_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created many features on the dataset based on group based anomaly detection. This features will be provided as inputs of\n",
    "a final model. It will be apply GradientBoost again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = XGBClassifier(n_estimators=1000,subsample=0.9,max_depth=6,random_state=10, max_features=0.9, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the same random state of train_test_split can garantee that the split is repetible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[features],df[target],\n",
    "                                                    shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the last statement ... just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train.index == x_train_origin.index).sum() / (x_train.index == x_train_origin.index).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time gbc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,gbc.predict(x_test[features]),digits=3))\n",
    "confusion_matrix(y_test,gbc.predict(x_test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly detection for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another strategy is creating AD for each variable (Feature) on the model input using the same top 20 tags for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 20 tags\n",
    "original_features = ['count_y','x51', 'x28','x26', 'x43','x60', 'x8','x54', 'x50','x14', 'x18','x24', 'x53','x23', 'x15','x22', 'x52','x42', 'x21', 'x36', 'x3']\n",
    "#original_features =[i for i in features if i not in new_features] #all tags\n",
    "features_individual_ad = original_features.copy()\n",
    "ad_maha = []\n",
    "for feat in original_features:\n",
    "    if not feat == 'count_y':\n",
    "        _model = MahalanobisOneclassClassifier(x_train_pos[[feat]], significance_level=0.01)\n",
    "        ad_maha.append(_model)\n",
    "        _ad_name = feat + '_ad'\n",
    "        df[_ad_name] = _model.predict_proba(df[[feat]].values)\n",
    "        features_individual_ad.append(_ad_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ad, x_test_ad, y_train_ad, y_test_ad = train_test_split(df[features_individual_ad],df[target],\n",
    "                                                    shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale_ad = StandardScaler()\n",
    "\n",
    "x_train_ad = pd.DataFrame(data=scale_ad.fit_transform(x_train_ad),columns=features_individual_ad,index=y_train_ad.index)\n",
    "x_test_ad = pd.DataFrame(data=scale_ad.transform(x_test_ad),columns=features_individual_ad,index=y_test_ad.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_ad = XGBClassifier(n_estimators=1000,subsample=0.9,max_depth=6,random_state=10, max_features=0.9, n_jobs=2)\n",
    "%time gbc_ad.fit(x_train_ad,y_train_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,gbc_ad.predict(x_test_ad[features_individual_ad]),digits=3))\n",
    "confusion_matrix(y_test,gbc_ad.predict(x_test_ad[features_individual_ad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,50))\n",
    "plot_importance(gbc_ad, ax=ax, height=1, importance_type=\"gain\", xlabel=\"Total Gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
